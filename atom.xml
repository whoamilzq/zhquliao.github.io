<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>清风恋语的个人博客</title>
  
  <subtitle>不积跬步，无以至千里，不积小流，无以成江海。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://3601blog.cn/"/>
  <updated>2019-09-08T12:27:03.261Z</updated>
  <id>https://3601blog.cn/</id>
  
  <author>
    <name>清风恋语</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2.现代处理器的结构和特点</title>
    <link href="https://3601blog.cn/posts/75d3effb/"/>
    <id>https://3601blog.cn/posts/75d3effb/</id>
    <published>2019-09-07T14:25:07.000Z</published>
    <updated>2019-09-08T12:27:03.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h2><p>处理器的每一次更新换代，都会增加若干新特性，这是很自然的。同时我们也会发现，老软件在新的处理器上跑得更快。这里面的原因很简单，处理器的设计者总是在想尽办法加快指令的执行。</p><a id="more"></a><p>早在 8086 时代，处理器就已经有了指令预取队列。当指令执行时，如果总线是空闲的（没有访问内存的操作），就可以在指令执行的同时预取指令并提前译码，这种做法是有效的，能大大加快程序的执行速度。</p><p>处理器可以做很多事情，换言之，能够执行各种不同的指令，完成不同的功能，但这些事情大都不会在一个时钟周期内完成。执行一条指令需要从内存中取指令、译码、访问操作数和结果，并进行移位、加法、减法、乘法以及其他任何需要的操作。</p><p>为了提高处理器的执行效率和速度，可以把一条指令的执行过程分解成若干个细小的步骤，并分配给相应的单元来完成。各个单元的执行是独立的、并行的。如此一来，各个步骤的执行在时间上就会重叠起来，这种执行指令的方法就是流水线（Pipe-Line）技术。比如，一条指令的执行过程分为取指令、译码和执行三个步骤，而且假定每个步骤都要花1 个时钟周期，那么，如图所示，如果采用顺序执行，则执行三条指令就要花 9 个时钟周期，每 3 个时钟周期才能得到一条指令的执行结果；如果采用 3 级流水线，则执行这三条指令只需 5 个时钟周期，每隔一个时钟周期就能得到一条指令的执行结果。</p><p><img src="https://ae01.alicdn.com/kf/Hd7694607cbd44349a01b3f3724070486c.jpg" alt="流水线的基本原理"></p><p>一个简单的流水线其实不过如此，但是，它仍有很大的改进空间。原因很简单，指令的执行过程仍然可以继续细分。一般来说，流水线的效率受执行时间最长的那一级的限制，要缩短各级的执行时间，就必须让每一级的任务减少，与此同时，就需要把一些复杂的任务再进行分解。比如，2000年之后推出的 Pentium 4 处理器采用了 NetBurst 微结构，它进一步分解指令的执行过程，采用了 31级超深流水线。</p><h2 id="高速缓存"><a href="#高速缓存" class="headerlink" title="高速缓存"></a>高速缓存</h2><p>影响处理器速度的另一个因素是存储器。从处理器内部向外看，它们分别是寄存器、内存和硬盘。当然，现在有的计算机已经用上了固态磁盘。</p><p>寄存器的速度是最快的，原因在于它使用了触发器，这是一种利用反馈原理制作的存储电路，在《穿越计算机的迷雾》那本书里，介绍得很清楚。触发器的工作速度是纳秒（ns）级别的，当然也可以用来做为内存的基本单元，即静态存储器（SRAM），缺点是成本太高，价格也不菲。所以，制作内存芯片的材料一般是电容和单个的晶体管，由于电容需要定时刷新，使得它的访问速度变得很慢，通常是几十个纳秒。因此，它也获得了一个恰当的名字：动态存储器（DRAM），我们所用的内存芯片，大部分都是 DRAM。最后，硬盘是机电设备，是机械和电子的混合体，它的速度最慢，通常在毫秒级（ms）。</p><p>在这种情况下，因为需要等待内存和硬盘这样的慢速设备，处理器便无法全速运行。为了缓解这一矛盾，高速缓存（Cache）技术应运而生。高速缓存是处理器与内存（DRAM）之间的一个静态存储器，容量较小，但速度可以与处理器匹配。高速缓存的用处源于程序在运行时所具有的局部性规律。首先，程序常常访问最近刚刚访问过的指令和数据，或者与它们相邻的指令和数据。比如，程序往往是序列化地从内存中取指令执行的，循环操作往往是执行一段固定的指令。当访问数据时，要访问的数据通常都被安排在一起；其次，一旦访问了某个数据，那么，不久之后，它可能会被再次访问。</p><p>利用程序运行时的局部性原理，可以把处理器正在访问和即将访问的指令和数据块从内存调入高速缓存中。于是，每当处理器要访问内存时，首先检索高速缓存。如果要访问的内容已经在高速缓存中，那么，很好，可以用极快的速度直接从高速缓存中取得，这称为命中（Hit）；否则，称为不中（Miss）。在不中的情况下，处理器在取得需要的内容之前必须重新装载高速缓存，而不只是直接到内存中去取那个内容。高速缓存的装载是以块为单位的，包括那个所需数据的邻近内容。为此，需要额外的时间来等待块从内存载入高速缓存，在该过程中所损失的时间称为不中惩罚（Miss Penalty）。</p><p>高速缓存的复杂性在于，每一款处理器可能都有不同的实现。在一些复杂的处理器内部，会存在多级 Cache，分别应用于各个独立的执行部件。</p><h2 id="乱序执行"><a href="#乱序执行" class="headerlink" title="乱序执行"></a>乱序执行</h2><p>为了实现流水线技术，需要将指令拆分成更小的可独立执行部分，即拆 分成微操作（Micro-Operations），简写为μ ops。</p><p>有些指令非常简单，因此只需要一个微操作。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add eax,ebx</span><br></pre></td></tr></table></figure><p>再比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add eax,[mem]</span><br></pre></td></tr></table></figure><p>可以拆分成两个微操作，一个用于从内存中读取数据并保存到临时寄存器，另一个用于将EAX寄存器和临时寄存器中的数值相加。</p><p>再举个例子，这条指令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add [mem],eax</span><br></pre></td></tr></table></figure><p>可以拆分成三个微操作，一个从内存中读数据，一个执行相加的动作，第3个用于将相加的结果写回到内存中。</p><p>一旦将指令拆分成微操作，处理器就可以在必要的时候乱序执行（Out-Of-Order Execution）程序。考虑以下例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mov eax,[mem1]</span><br><span class="line">shl eax,5</span><br><span class="line">add eax,[mem2]</span><br><span class="line">mov [mem3],eax</span><br></pre></td></tr></table></figure><p>这里，指令add eax,[mem2]可以拆分为两个微操作。如此一来，在执行逻辑左移指令的同时，处理器可以提前从内存中读取mem2的内容。典型地，如果数据不在高速缓存中（不中），那么处理器在获取mem1的内容之后，会立即开始获取mem2的内容，与此同时，shl指令的执行早就开始了。</p><p>将指令拆分成微操作，也可以使得堆栈的操作更有效率。考虑以下代码片断：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">push eax</span><br><span class="line">call func</span><br></pre></td></tr></table></figure><p>这里，push eax指令可以拆分成两个微操作，即可以表述为以下的等价形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sub esp,4</span><br><span class="line">mov [esp],eax</span><br></pre></td></tr></table></figure><p>这就带来了一个好处，即使EAX寄存器的内容还没有准备好，微操作sub esp,4也可以执行。call指令执行时需要在当前堆栈中保存返回地址，在以前，该操作只能等待push eax指令执行结束，因为它需要ESP的新值。感谢微操作，现在，call指令在微操作sub esp,4执行结束时就可以无延迟地立即开始执行。</p><h2 id="寄存器重命名"><a href="#寄存器重命名" class="headerlink" title="寄存器重命名"></a>寄存器重命名</h2><p>考虑以下例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mov eax,[mem1]</span><br><span class="line">shl eax,3</span><br><span class="line">mov [mem2],eax</span><br><span class="line">mov eax,[mem3]</span><br><span class="line">add eax,2</span><br><span class="line">mov [mem4],eax</span><br></pre></td></tr></table></figure><p>以上代码片断做了两件事，但互不相干：将mem1里的内容左移3次（乘以8），并将mem3里的内容加2。如果我们为最后三条指令使用不同的寄存器，那么将更明显地看出这两件事的无关性。并且，事实上，处理器实际上也是这样做的。处理器为最后三条指令使用了另一个不同的临时寄存器，因此，左移（乘法）和加法可以并行地处理。</p><p>IA-32架构的处理器只有8个32位通用寄存器，但通常都会被我们全部派上用场（甚至还觉得不够）。因此，我们不能奢望在每个计算当中都使用新的寄存器。不过，在处理器内部，却有大量的临时寄存器可用，处理器可以重命名这些寄存器以代表一个逻辑寄存器，比如EAX。</p><p>寄存器重命名以一种完全自动和非常简单的方式工作。每当指令写逻辑寄存器时，处理器就为那个逻辑寄存器分配一个新的临时寄存器。再来看一个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mov eax,[mem1]</span><br><span class="line">mov ebx,[mem2]</span><br><span class="line">add ebx,eax</span><br><span class="line">shl eax,3</span><br><span class="line">mov [mem3],eax</span><br><span class="line">mov [mem4],ebx</span><br></pre></td></tr></table></figure><p>假定现在mem1的内容在高速缓存里，可以立即取得，但mem2的内容不在高速缓存中。这意味着，左移操作可以在加法之前开始（使用临时寄存器代替EAX）。为左移的结果使用一个新的临时寄存器，其好处是EAX寄存器中仍然是以前的内容，它将一直保持这个值，直到EBX寄存器中的内容就绪，然后同它一起做加法运算。如果没有寄存器重命名机制，左移操作将不得不等待从内存中读取mem2的内容到EBX寄存器以及加法操作完成。</p><p>在所有的操作都完成之后，那个代表EAX寄存器最终结果的临时寄存器的内容被写入真实的EAX寄存器，该处理过程称为引退（Retirement）。</p><p>所有通用寄存器，堆栈指针、标志、浮点寄存器，甚至段寄存器都有可能被重命名。</p><h2 id="分支目标预测"><a href="#分支目标预测" class="headerlink" title="分支目标预测"></a>分支目标预测</h2><p>流水线并不是百分之百完美的解决方案。实际上，有很多潜在的因素会使得流水线不能达到最佳的效率。一个典型的情况是，如果遇到一条转移指令，则后面那些已经进入流水线的指令就都无效了。换句话说，我们必须清空（Flush）流水线，从要转移到的目标位置处重新取指令放入流水线。</p><p>在现代处理器中，流水线操作分为很多步骤，包括取指令、译码、寄存器分配和重命名、微操作排序、执行和引退。指令的流水线处理方式允许处理器同时做很多事情。在一条指令执行时，下一条指令正在获取和译码。</p><p>流水线的最大问题是代码中经常存在分支。举个例子来说，一个条件转移允许指令流前往任意两个方向。如果这里只有一个流水线，那么，直到那个分支开始执行，在此之前，处理器将不知道应该用哪个分支填充流水线。流水线越长，处理器在用错误的分支填充流水线时，浪费的时间越多。</p><p>随着复杂架构下的流水线变得越来越长，程序分支带来的问题开始变得很大。让处理器的设计者不能接受，毕竟不中处罚的代价越来越高。<br>为了解决这个问题，在1996年的Pentium Pro处理器上，引入了分支预测技术（Branch Prediction）。分支预测的核心问题是，转移是发生还是不会发生。换句话说，条件转移指令的条件会不会成立。举个例子来说：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jne branch5</span><br></pre></td></tr></table></figure><p>在这条指令还没有执行的时候，处理器就必须提前预测相等的条件在这条指令执行的时候是否成立。这当然是很困难的，几乎不可能。想想看，如果能够提前知道结果，还执行这些指令干嘛。</p><p>但是，从统计学的角度来看，有些事情一旦出现，下一次还会出现的概率较大。一个典型的例子就是循环，比如下面的程序片断：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xor si,si</span><br><span class="line">lops:</span><br><span class="line">    …</span><br><span class="line">    cmp si,20</span><br><span class="line">    jnz lops</span><br></pre></td></tr></table></figure><p>当jnz指令第一次执行时，转移一定会发生。那么，处理器就可以预测，下一次它还会转移到标号lops处，而不是顺序往下执行。事实上，这个预测通常是很准的。</p><p>在处理器内部，有一个小容量的高速缓存器，叫分支目标缓存器（Branch Target Buffer，BTB）。当处理器执行了一条分支语句后，它会在BTB中记录当前指令的地址、分支目标的地址，以及本次分支预测的结果。下一次，在那条转移指令实际执行前，处理器会查找BTB，看有没有最近的转移记录。如果能找到对应的条目，则推测执行和上一次相同的分支，把该分支的指令送入流水线。</p><p>当该指令实际执行时，如果预测是失败的，那么，清空流水线，同时刷新BTB中的记录。这个代价较大。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;流水线&quot;&gt;&lt;a href=&quot;#流水线&quot; class=&quot;headerlink&quot; title=&quot;流水线&quot;&gt;&lt;/a&gt;流水线&lt;/h2&gt;&lt;p&gt;处理器的每一次更新换代，都会增加若干新特性，这是很自然的。同时我们也会发现，老软件在新的处理器上跑得更快。这里面的原因很简单，处理器的设计者总是在想尽办法加快指令的执行。&lt;/p&gt;
    
    </summary>
    
      <category term="操作系统编程" scheme="https://3601blog.cn/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="从实模式到保护模式" scheme="https://3601blog.cn/tags/%E4%BB%8E%E5%AE%9E%E6%A8%A1%E5%BC%8F%E5%88%B0%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>1.IA-32架构的基本执行环境</title>
    <link href="https://3601blog.cn/posts/9ec7c8da/"/>
    <id>https://3601blog.cn/posts/9ec7c8da/</id>
    <published>2019-09-06T14:18:54.000Z</published>
    <updated>2019-09-08T12:26:58.344Z</updated>
    
    <content type="html"><![CDATA[<h2 id="寄存器的扩展"><a href="#寄存器的扩展" class="headerlink" title="寄存器的扩展"></a>寄存器的扩展</h2><p>在 16 位处理器内，有 8 个通用寄存器 AX、BX、CX、DX、SI、DI、BP 和 SP，其中，前 4 个还可以拆分成两个独立的 8 位寄存器来用，即 AH、AL、BH、BL、CH、CL、DH 和 DL。32 位处理器在 16 位处理器的基础上，扩展了这 8 个通用寄存器的长度，组成EAX、EBX、ECX、EDX、ESI、EDI、EBP 这 8 个 32 位存储器。</p><a id="more"></a><p><img src="https://ae01.alicdn.com/kf/H405b10310e3f4d339358278cbeb5fa54x.jpg" alt="32位处理器内部的通用寄存器"></p><h3 id="32位寄存器的使用"><a href="#32位寄存器的使用" class="headerlink" title="32位寄存器的使用"></a>32位寄存器的使用</h3><p>为了在汇编语言程序中使用经过扩展（Extend）的寄存器，需要给它们命名，它们的名字分别是 EAX、EBX、ECX、EDX、ESI、EDI、ESP 和 EBP。可以在程序中使用这些寄存器，即使是在实模式下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov eax,0xf0000005</span><br><span class="line">mov ecx,eax</span><br><span class="line">add edx,ecx</span><br></pre></td></tr></table></figure><p>但是，就像以上指令所示的那样，指令的源操作数和目的操作数必须具有相同的长度，个别特殊用途的指令除外。因此，像这样的搭配是不允许的，在程序编译时，编译器会报告错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mov eax,cx ;错误的汇编语言指令</span><br></pre></td></tr></table></figure><p>如果目的操作数是 32 位寄存器，源操作数是立即数，那么，立即数被视为 32 位的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mov eax,0xf5 ;EAX←0x000000f5</span><br></pre></td></tr></table></figure><p>32 位通用寄存器的高 16 位是不可独立使用的，但低 16 位保持同 16 位处理器的兼容性。因此，在任何时候它们都可以照往常一样使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov ah,0x02</span><br><span class="line">mov al,0x03</span><br><span class="line">add ax,si</span><br></pre></td></tr></table></figure><h3 id="32位处理器与-16-位处理器的区别"><a href="#32位处理器与-16-位处理器的区别" class="headerlink" title="32位处理器与 16 位处理器的区别"></a>32位处理器与 16 位处理器的区别</h3><p>可以在 32 位处理器上运行 16 位处理器上的软件。但是，它并不是 16 位处理器的简单增强。事实上，32 位处理器有自己的 32 位工作模式，一般，32 位模式特指 32 位保护模式。在这种模式下，可以完全、充分地发挥处理器的性能。同时，在这种模式下，处理器可以使用它全部的 32根地址线，能够访问 4GB 内存。</p><p>在 32 位模式下，为了生成 32 位物理地址，处理器需要使用 32 位的指令指针寄存器。为此，32 位处理器扩展了 IP，使之达到 32 位，即 EIP。当它工作在 16 位模式下时，依然使用 16 位的 IP；工作在 32 位模式下时，使用的是全部的 32 位 EIP。和往常一样，即使是在 32 位模式下，EIP 寄存器也只由处理器内部使用，程序中是无法直接访问的。对 IP 和 EIP 的修改通常是用某些指令隐式进行的，这此指令包括 JMP、CALL、RET 和 IRET 等等。</p><p><img src="https://ae01.alicdn.com/kf/Hc27ce111ccd74329a2f89dfb14e308325.jpg" alt="32位处理器的指令指针、标志和段寄存器"></p><p>另外，在 16 位处理器中，标志寄存器 FLAGS 是 16 位的，在 32 位处理器中，扩展到了 32 位，低 16 位和原先保持一致。关于 EFLAGS 中的各个标志位，将在后面的章节中逐一介绍。</p><p>在 32 位模式下，对内存的访问从理论上来说不再需要分段，因为它有 32 根地址线，可以自由访问任何一个内存位置。但是，IA-32 架构的处理器是基于分段模型的，因此，32 位处理器依然需要以段为单位访问内存，即使它工作在 32 位模式下。</p><p>不过，它也提供了一种变通的方案，即，只分一个段，段的基地址是 0x00000000，段的长度（大小）是 4GB。在这种情况下，可以视为不分段，即平坦模型（Flat Mode）。</p><p>每个程序都有属于自己的内存空间。在 16 位模式下，一个程序可以自由地访问不属于它的内存位置，甚至可以对那些地方的内容进行修改。这当然是不安全的，也不合法，但却没有任何机制来限制这种行为。在 32 位模式下，处理器要求在加载程序时，先定义该程序所拥有的段，然后允许使用这些段。定义段时，除了基地址（起始地址）外，还附加了段界限、特权级别、类型等属性。当程序访问一个段时，处理器将用固件实施各种检查工作，以防止对内存的违规访问。</p><p>在 32 位模式下，传统的段寄存器，如 CS、SS、DS、ES，保存的不再是 16位段基地址，而是段的选择子，即，用于选择所要访问的段，因此，严格地说，它的新名字叫做段选择器。除了段选择器之外，每个段寄存器还包括一个 64 位的不可见部分，称为描述符高速缓存器，里面有段的基地址和各种访问属性。这部分内容程序不可访问，由处理器自动使用。</p><p>最后，32 位处理器增加了两个额外的段寄存器 FS 和 GS。对于某些复杂的程序来说，多出两个段寄存器可能会令它们感到高兴。</p><h2 id="基本的工作模式"><a href="#基本的工作模式" class="headerlink" title="基本的工作模式"></a>基本的工作模式</h2><p>8086 具有 16 位的段寄存器、指令指针寄存器和通用寄存器（CS、SS、DS、ES、IP、AX、BX、CX、DX、SI、DI、BP、SP），因此，我们称它为 16 位的处理器。尽管它可以访问 1MB的内存，但是只能分段进行，而且由于只能使用 16 位的段内偏移量，故段的长度最大只能是64KB。8086 只有一种工作模式，即实模式。当然，这个名称是后来才提出来的。</p><p>1982 年的时候，Intel 公司推出了 80286 处理器。这也是一款 16 位的处理器，大部分的寄存器都和 8086 处理器一样。因此，80286 和 8086 一样，因为段寄存器是 16 位的，而且只能使用 16 位的偏移地址，在实模式下只能使用 64KB 的段；尽管它有 24 根地址线，理论上可以访问 $2^24$，即 16MB 的内存,但依然只能分成多个段来进行。</p><p>但是，80286 和 8086 不一样的地方在于，它第一次提出了保护模式的概念。在保护模式下，段寄存器中保存的不再是段地址，而是段选择子，真正的段地址位于段寄存器的描述符高速缓存中，是 24 位的。因此，运行在保护模式下的 80286 处理器可以访问全部 16MB 内存。</p><p>80286 处理器访问内存时，不再需要将段地址左移，因为在段寄存器的描述符高速缓存器中有 24 位的段物理基地址。这样一来，段可以位于 16MB 内存空间中的任何位置，而不再限于低端 1MB 范围内，也不必非得是位于 16 字节对齐的地方。不过，由于 80286 的通用寄存器是 16 位的，只能提供 16 位的偏移地址，因此，和 8086 一样，即使是运行在保护模式下，段的长度依然不能超过 64KB。对段长度的限制妨碍了 80286 处理器的应用，这就是 16位保护模式很少为人所知的原因。</p><p>实模式等同于 8086 模式，一般，实模式和 16 位保护模式统称 16 位模式。在 16 位模式下，数据的大小是 8 位或者 16 位的；控制转移和内存访问时，偏移量也是 16 位的。</p><p>1985 年的 80386 处理器是 Intel 公司的第一款 32 位产品，而且获得了极大成功，是后续所有 32 位产品的基础。本书中的绝大多数例子，都可以在 80386 上运行。和 8086/80286 不同，80386 处理器的寄存器是 32 位的，而且拥有 32 根地址线，可以访问 $2^32$，即 4GB 的内存。</p><p>80386，以及所有后续的 32 位处理器，都兼容实模式，可以运行实模式下的 8086 程序。而且，在刚加电时，这些处理器都自动处于实模式下，此时，它相当于一个非常快速的 8086处理器。只有在进行一番设置之后，才能运行在保护模式下。</p><p>在保护模式下，所有的 32 位处理器都可以访问多达 4GB 的内存，它们可以工作在分段模型下，每个段的基地址是 32 位的，段内偏移量也是 32 位的，因此，段的长度不受限制。在最典型的情况下，可以将整个 4GB 内存定义成一个段来处理，这就是所谓的平坦模式。在平坦模式下，可以执行 4GB 范围内的控制转移，也可以使用 32 位的偏移量访问任何 4GB 范围内的任何位置。32 位保护模式兼容 80286 的 16 位保护模式。</p><p>除了保护模式，32 位处理器还提供虚拟 8086 模式（V86 模式），在这种模式下，IA-32 处理器被模拟成多个 8086 处理器并行工作。V86 模式是保护模式的一种，可以在保护模式下执行多个 8086 程序。传统上，要执行 8086 程序，处理器必须工作在实模式下。在这种情况下，为 32 位保护模式写的程序就不能运行。但是，V86 模式提供了让它们在一起同时运行的条件。</p><p>V86 模式曾经很有用，因为在那个时候，8086 程序很多，而 32 位应用程序很少，这个过渡期是必需的。现在，这种工作模式已经基本无用了。</p><h2 id="线性地址"><a href="#线性地址" class="headerlink" title="线性地址"></a>线性地址</h2><p>为 IA-32 处理器编程，访问内存时，需要在程序中给出段地址和偏移量，因为分段是 IA-32架构的基本特征之一。传统上，段地址和偏移地址称为逻辑地址，偏移地址叫做有效地址（Effective Address，EA），在指令中给出有效地址的方式叫做寻址方式（Addressing Mode）。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inc word [bx+si+0x06]</span><br></pre></td></tr></table></figure><p>在这里，指令中使用的是基址加变址的方式来寻找最终的操作数。</p><p>段的管理是由处理器的段部件负责进行的，段部件将段地址和偏移地址相加，得到访问内存的地址。一般来说，段部件产生的地址就是物理地址。</p><p>IA-32 处理器支持多任务。在多任务环境下，任务的创建需要分配内存空间；当任务终止后，还要回收它所占用的内存空间。在分段模型下，内存的分配是不定长的，程序大时，就分配一大块内存；程序小时，就分配一小块。时间长了，内存空间就会碎片化，就有可能出现一种情况：内存空间是有的，但都是小块，无法分配给某个任务。为了解决这个问题，IA-32 处理器支持分页功能，分页功能将物理内存空间划分成逻辑上的页。页的大小是固定的，一般为 4KB，通过使用页，可以简化内存管理。</p><p>如图所示，当页功能开启时，段部件产生的地址就不再是物理地址了，而是线性地址（Linear Address），线性地址还要经页部件转换后，才是物理地址。</p><p><img src="https://ae01.alicdn.com/kf/Hec41d72daf6348868a310a7cea4b24b46.jpg" alt="线性地址和线性地址空间"></p><p>线性地址的概念用来描述任务的地址空间。如图 10-3 所示，IA-32 处理器上的每个任务都拥有4GB 的虚拟内存空间，这是一段长 4GB 的平坦空间，就像一段平直的线段，因此叫线性地址空间。相应地，由段部件产生的地址，就对应着线性地址空间上的每一个点，这就是线性地址。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;寄存器的扩展&quot;&gt;&lt;a href=&quot;#寄存器的扩展&quot; class=&quot;headerlink&quot; title=&quot;寄存器的扩展&quot;&gt;&lt;/a&gt;寄存器的扩展&lt;/h2&gt;&lt;p&gt;在 16 位处理器内，有 8 个通用寄存器 AX、BX、CX、DX、SI、DI、BP 和 SP，其中，前 4 个还可以拆分成两个独立的 8 位寄存器来用，即 AH、AL、BH、BL、CH、CL、DH 和 DL。32 位处理器在 16 位处理器的基础上，扩展了这 8 个通用寄存器的长度，组成EAX、EBX、ECX、EDX、ESI、EDI、EBP 这 8 个 32 位存储器。&lt;/p&gt;
    
    </summary>
    
      <category term="操作系统编程" scheme="https://3601blog.cn/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="从实模式到保护模式" scheme="https://3601blog.cn/tags/%E4%BB%8E%E5%AE%9E%E6%A8%A1%E5%BC%8F%E5%88%B0%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>树和二叉树</title>
    <link href="https://3601blog.cn/posts/dd5c0739/"/>
    <id>https://3601blog.cn/posts/dd5c0739/</id>
    <published>2019-09-04T07:51:42.000Z</published>
    <updated>2019-09-06T13:01:45.018Z</updated>
    
    <content type="html"><![CDATA[<p>树型结构是一种重要的非线性数据结构。其中以树和二叉树最为重要，直观来看，树是以分支关系定义的层次结构。树结构在客观世界中广泛存在，如人类社会的族谱和各种社会组织机构都可用树来形象表示。树在计算机领域中也得到广泛应用，如在编译程序中，可以用树来表示源程序的语法结构。又如在数据库系统中，树形结构也是信息的重要组织形式之一。</p><a id="more"></a><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><p><strong>树</strong>（Tree）是 $n(n\geq 0)$ 个结点的有限集。在任意一棵非空树中：<br>（1）有且仅有一个特定的称为根（Root）的结点<br>（2）当 $n&gt;1$ 时，其余结点可分为 $m(m&gt;0)$ 个互相不相交的有限集 $T_1,T_2,…,T_m$，其中每个集合本身又是一棵树，并且称为根的子树（SubTree）。</p><h3 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h3><ul><li><strong>结点的度：</strong> 树中某个结点的子树的个数称为该结点的度。</li><li><strong>树的度：</strong> 树中所有结点的度的最大值称为树的度。通常将度为$m$的树称为$m$次树。</li><li><strong>分支结点：</strong> 树中度不为 0 的结点。</li><li><strong>叶子结点：</strong> 树中度为 0 的结点。</li><li><strong>单分支结点：</strong> 树中度为 1 的结点。</li><li><strong>结点层次和树的高度：</strong> 树中每个结点都处在一定的层次上。<strong>结点层次</strong>或<strong>结点深度</strong>是在树根结点开始定义的，根结点为第一层，他的孩子结点为第二层，依次类推。树中结点的最大层次称为<strong>树的高度</strong></li></ul><h3 id="树的性质"><a href="#树的性质" class="headerlink" title="树的性质"></a>树的性质</h3><ol><li>树中的结点数 $=$ 所有结点的度数和 $+$ 1</li><li>度为$m$的树中第$i$层上最多有$m^{i-1}$个结点（$m\geq1$）</li><li>高度为$h$的$m$次树最多有$\frac{m^h-1}{m-1}$个结点</li><li>具有$n$个结点的$m$次树的最小高度为$[\log_m(n(m-1)+1) ]$（取整）</li></ol><h3 id="树的遍历"><a href="#树的遍历" class="headerlink" title="树的遍历"></a>树的遍历</h3><p>有一棵树结构如下图所示</p><p><img src="https://pic.superbed.cn/item/5d6f73d3451253d178212474.png" alt="树"></p><p>1.<strong>先根遍历</strong>的过程如下：<br>（1）访问根结点<br>（2）按照从左到右的顺序先根遍历根结点的每一棵子树。<br>按照先根遍历的方法遍历上面所示的树得到的结点序列为：ABEFCGJDHIKLM。<br>先根遍历的第一个元素即为根节点的节点值。</p><p>2.<strong>后根遍历</strong>的过程如下：<br>（1）按照从左到右的顺序先根遍历根结点的每一棵子树。<br>（2）访问根结点<br>按照后根遍历的方法遍历上面所示的树得到的结点序列为：EFBJGCHKLMIDA。<br>后根遍历的最后一个元素即为根节点的节点值。</p><p>1.<strong>层次遍历</strong>的过程如下：<br>（1）从根结点开始按照从上到下、从左到右的顺序访问树中的每一个结点。<br>按照层次遍历的方法遍历上面所示的树得到的结点序列为：ABCDEFGHIJKLM。<br>层次遍历的第一个元素即为根节点的节点值。</p><h2 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h2><p><strong>二叉树（Binary Tree）</strong>是另一种树形结构，它的特点是每个结点至多只有两棵子树（即二叉树中不存在度大于2的结点），并且，二叉树的子树有左右之分，其次序不能任意颠倒。</p><h3 id="二叉树的性质"><a href="#二叉树的性质" class="headerlink" title="二叉树的性质"></a>二叉树的性质</h3><p>性质1：在二叉树的第 $i$ 层结点数 $\leq 2^{i-1}$，$i\geq 1$。<br>性质2：深度为 $k$ 的二叉树结点数 $\leq 2^k-1$， $k\geq 1$。<br>性质3：对任何一棵二叉树 $T$，如果其终端结点数为 $n$，度为2的结点数为 $m$，则 $n=m+1$。<br>性质4：具有 $n$ 个结点的完全二叉树的深度为 $\log_2{n}+1$。<br>性质5：如果一棵有 $n$ 个结点的完全二叉树（其深度为 $\log_2{n}+1$）的结点按层编号（从第1层到第 $\log_2{n}+1$ 层从左到右），则对任一结点 $i(1\leq i\leq n)$ 有：<br>（1）如果 $i=1$，则结点 $i$ 是二叉树的根，无双亲；如果其双亲 $PARENT(i)$ 是结点 $i/2$。<br>（2）如果 $2i&gt;n$，则结点 $i$ 无左孩子（结点 $i$ 为叶子结点）；否则其左孩子 $LCHILD(i)$ 是结点 $2i$。<br>（3）如果 $2i+1&gt;n$，则结点 $i$ 无右孩子；否则其左孩子 $RCHILD(i)$ 是结点 $2i+1$。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;树型结构是一种重要的非线性数据结构。其中以树和二叉树最为重要，直观来看，树是以分支关系定义的层次结构。树结构在客观世界中广泛存在，如人类社会的族谱和各种社会组织机构都可用树来形象表示。树在计算机领域中也得到广泛应用，如在编译程序中，可以用树来表示源程序的语法结构。又如在数据库系统中，树形结构也是信息的重要组织形式之一。&lt;/p&gt;
    
    </summary>
    
      <category term="数据结构" scheme="https://3601blog.cn/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="C语言" scheme="https://3601blog.cn/tags/C%E8%AF%AD%E8%A8%80/"/>
    
      <category term="数据结构" scheme="https://3601blog.cn/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://3601blog.cn/posts/4a17b156/"/>
    <id>https://3601blog.cn/posts/4a17b156/</id>
    <published>2019-09-02T01:10:52.390Z</published>
    <updated>2019-09-04T12:36:45.470Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="https://3601blog.cn/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="其他" scheme="https://3601blog.cn/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
</feed>
